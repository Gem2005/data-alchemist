# Azure OpenAI Integration Guide

## Current Status ‚úÖ

The Data Alchemist application now includes **real Azure OpenAI integration** to replace the previous mock responses. The system automatically detects whether Azure OpenAI is configured and falls back to intelligent mock responses when it's not available.

## Features Implemented

### ü§ñ Real AI-Powered Features
- **Natural Language Data Querying**: Ask questions about your data in plain English
- **Smart Rule Recommendations**: AI analyzes data patterns and suggests optimization rules
- **Data Quality Suggestions**: AI identifies data gaps and improvement opportunities
- **Business Rule Generation**: Convert natural language descriptions into structured rules

### üîÑ Intelligent Fallback System
- Automatically detects Azure OpenAI configuration
- Falls back to smart pattern-matching when Azure OpenAI is unavailable
- Visual indicator shows current AI mode (Azure OpenAI vs Fallback)
- No interruption to user experience regardless of configuration

## Configuration

### 1. Azure OpenAI Setup

First, you need an Azure OpenAI resource:

1. **Create Azure OpenAI Resource**:
   - Go to [Azure Portal](https://portal.azure.com)
   - Create a new "Azure OpenAI" resource
   - Choose your subscription, resource group, and region
   - Select a pricing tier

2. **Deploy a Model**:
   - In your Azure OpenAI resource, go to "Model deployments"
   - Deploy a chat model like `gpt-4` or `gpt-35-turbo`
   - Note the deployment name you choose

3. **Get Configuration Values**:
   - **Endpoint**: Found in resource overview (e.g., `https://your-resource.openai.azure.com/`)
   - **API Key**: Found under "Keys and Endpoint" section
   - **Deployment Name**: The name you gave your model deployment

### 2. Environment Variables

Create a `.env.local` file in your project root with:

```env
# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key-here
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# Optional: Client-side detection (no API key!)
NEXT_PUBLIC_AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
NEXT_PUBLIC_AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4
```

‚ö†Ô∏è **Security Note**: Never put API keys in `NEXT_PUBLIC_` variables as they're exposed to browsers.

### 3. Restart the Application

After adding environment variables:

```bash
npm run dev
```

You should see the AI Assistant indicator change from "Fallback Mode" to "Azure OpenAI" with a green status dot.

## How It Works

### Architecture
- **Client-Side Service** (`/src/lib/azureOpenAI.ts`): Handles AI requests and fallback logic
- **Server-Side API** (`/src/app/api/ai/route.ts`): Securely processes Azure OpenAI requests
- **AI Assistant Component** (`/src/components/AIAssistant.tsx`): Updated to use real AI services

### Request Flow
1. User makes AI request in the UI
2. Client-side service checks if Azure OpenAI is configured
3. If configured: Makes secure API call to `/api/ai` endpoint
4. Server-side API calls Azure OpenAI with proper authentication
5. Response is processed and returned to user
6. If not configured: Uses intelligent fallback responses

### Fallback Behavior
When Azure OpenAI is not configured, the system provides:
- Pattern-based natural language queries
- Rule recommendations based on data analysis
- Data improvement suggestions using heuristics
- All functionality remains available with reduced AI sophistication

## Testing the Integration

### 1. Without Azure OpenAI (Fallback Mode)
- Start the app: `npm run dev`
- Look for orange "Fallback Mode" indicator
- Test queries like "Show tasks with duration more than 2 phases"
- Expect intelligent pattern-matching responses

### 2. With Azure OpenAI (Full AI Mode)
- Configure environment variables as above
- Restart the app: `npm run dev`
- Look for green "Azure OpenAI" indicator
- Test the same queries for enhanced AI responses
- Try complex queries like "Find workers who might be overloaded based on their skills and task assignments"

## Benefits of This Implementation

### ‚úÖ **Security First**
- API keys never exposed to client
- All Azure OpenAI calls happen server-side
- Proper error handling and retry logic

### ‚úÖ **User Experience**
- No disruption when Azure OpenAI is unavailable
- Clear visual indicators of AI mode
- Consistent interface regardless of backend

### ‚úÖ **Development Friendly**
- Works immediately without any configuration
- Easy to test and demonstrate
- Progressive enhancement when Azure OpenAI is added

### ‚úÖ **Production Ready**
- Proper error boundaries and fallbacks
- Logging and monitoring hooks in place
- Scalable architecture for additional AI features

## Advanced Configuration

### Custom Prompts
You can modify the AI prompts in `/src/app/api/ai/route.ts` to customize the AI behavior for your specific use case.

### Adding New AI Features
The architecture makes it easy to add new AI-powered features:

1. Add new request type to `AIRequest` interface
2. Implement handler in the API route
3. Add method to `AzureOpenAIService`
4. Update UI components to use the new feature

### Monitoring and Analytics
The system logs Azure OpenAI usage and errors. You can extend this for:
- Usage analytics
- Cost monitoring
- Performance tracking
- A/B testing different prompts

## Troubleshooting

### Common Issues

**"Fallback Mode" when Azure OpenAI should be configured**:
- Check environment variables are in `.env.local`
- Verify endpoint URL format (should end with `/`)
- Confirm API key is correct
- Check deployment name matches your Azure resource

**API Errors**:
- Verify your Azure OpenAI resource is active
- Check if you have quota remaining
- Ensure the deployment name exists
- Confirm API key has proper permissions

**Network Issues**:
- Check if your environment can reach Azure endpoints
- Verify firewall/proxy settings
- Test the endpoint URL in a browser (should show OpenAI swagger UI)

## Next Steps

This implementation provides a solid foundation for expanding AI capabilities:

1. **Enhanced Data Parsing**: Use AI for intelligent column mapping
2. **Advanced Validation**: AI-powered data quality checks
3. **Natural Language Rule Creation**: More sophisticated rule parsing
4. **Predictive Analytics**: AI-driven resource allocation optimization
5. **Multi-language Support**: Localized AI interactions

The architecture is designed to scale with your AI ambitions while maintaining a great user experience regardless of configuration complexity.
